{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>SVM-Multi-class & Multi-Label Classification</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Multi-class and Multi-Label Classification Using Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, make_scorer, hamming_loss\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline as make_pipeline_imb\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Download the Anuran Calls (MFCCs) Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Frogs = pd.read_csv('../Data/Frogs_MFCCs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7195, 26)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MFCCs_ 1</th>\n",
       "      <th>MFCCs_ 2</th>\n",
       "      <th>MFCCs_ 3</th>\n",
       "      <th>MFCCs_ 4</th>\n",
       "      <th>MFCCs_ 5</th>\n",
       "      <th>MFCCs_ 6</th>\n",
       "      <th>MFCCs_ 7</th>\n",
       "      <th>MFCCs_ 8</th>\n",
       "      <th>MFCCs_ 9</th>\n",
       "      <th>MFCCs_10</th>\n",
       "      <th>...</th>\n",
       "      <th>MFCCs_17</th>\n",
       "      <th>MFCCs_18</th>\n",
       "      <th>MFCCs_19</th>\n",
       "      <th>MFCCs_20</th>\n",
       "      <th>MFCCs_21</th>\n",
       "      <th>MFCCs_22</th>\n",
       "      <th>Family</th>\n",
       "      <th>Genus</th>\n",
       "      <th>Species</th>\n",
       "      <th>RecordID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.152936</td>\n",
       "      <td>-0.105586</td>\n",
       "      <td>0.200722</td>\n",
       "      <td>0.317201</td>\n",
       "      <td>0.260764</td>\n",
       "      <td>0.100945</td>\n",
       "      <td>-0.150063</td>\n",
       "      <td>-0.171128</td>\n",
       "      <td>0.124676</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108351</td>\n",
       "      <td>-0.077623</td>\n",
       "      <td>-0.009568</td>\n",
       "      <td>0.057684</td>\n",
       "      <td>0.118680</td>\n",
       "      <td>0.014038</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.171534</td>\n",
       "      <td>-0.098975</td>\n",
       "      <td>0.268425</td>\n",
       "      <td>0.338672</td>\n",
       "      <td>0.268353</td>\n",
       "      <td>0.060835</td>\n",
       "      <td>-0.222475</td>\n",
       "      <td>-0.207693</td>\n",
       "      <td>0.170883</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.090974</td>\n",
       "      <td>-0.056510</td>\n",
       "      <td>-0.035303</td>\n",
       "      <td>0.020140</td>\n",
       "      <td>0.082263</td>\n",
       "      <td>0.029056</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.152317</td>\n",
       "      <td>-0.082973</td>\n",
       "      <td>0.287128</td>\n",
       "      <td>0.276014</td>\n",
       "      <td>0.189867</td>\n",
       "      <td>0.008714</td>\n",
       "      <td>-0.242234</td>\n",
       "      <td>-0.219153</td>\n",
       "      <td>0.232538</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050691</td>\n",
       "      <td>-0.023590</td>\n",
       "      <td>-0.066722</td>\n",
       "      <td>-0.025083</td>\n",
       "      <td>0.099108</td>\n",
       "      <td>0.077162</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.224392</td>\n",
       "      <td>0.118985</td>\n",
       "      <td>0.329432</td>\n",
       "      <td>0.372088</td>\n",
       "      <td>0.361005</td>\n",
       "      <td>0.015501</td>\n",
       "      <td>-0.194347</td>\n",
       "      <td>-0.098181</td>\n",
       "      <td>0.270375</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.136009</td>\n",
       "      <td>-0.177037</td>\n",
       "      <td>-0.130498</td>\n",
       "      <td>-0.054766</td>\n",
       "      <td>-0.018691</td>\n",
       "      <td>0.023954</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.087817</td>\n",
       "      <td>-0.068345</td>\n",
       "      <td>0.306967</td>\n",
       "      <td>0.330923</td>\n",
       "      <td>0.249144</td>\n",
       "      <td>0.006884</td>\n",
       "      <td>-0.265423</td>\n",
       "      <td>-0.172700</td>\n",
       "      <td>0.266434</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048885</td>\n",
       "      <td>-0.053074</td>\n",
       "      <td>-0.088550</td>\n",
       "      <td>-0.031346</td>\n",
       "      <td>0.108610</td>\n",
       "      <td>0.079244</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MFCCs_ 1  MFCCs_ 2  MFCCs_ 3  MFCCs_ 4  MFCCs_ 5  MFCCs_ 6  MFCCs_ 7  \\\n",
       "0       1.0  0.152936 -0.105586  0.200722  0.317201  0.260764  0.100945   \n",
       "1       1.0  0.171534 -0.098975  0.268425  0.338672  0.268353  0.060835   \n",
       "2       1.0  0.152317 -0.082973  0.287128  0.276014  0.189867  0.008714   \n",
       "3       1.0  0.224392  0.118985  0.329432  0.372088  0.361005  0.015501   \n",
       "4       1.0  0.087817 -0.068345  0.306967  0.330923  0.249144  0.006884   \n",
       "\n",
       "   MFCCs_ 8  MFCCs_ 9  MFCCs_10  ...  MFCCs_17  MFCCs_18  MFCCs_19  MFCCs_20  \\\n",
       "0 -0.150063 -0.171128  0.124676  ... -0.108351 -0.077623 -0.009568  0.057684   \n",
       "1 -0.222475 -0.207693  0.170883  ... -0.090974 -0.056510 -0.035303  0.020140   \n",
       "2 -0.242234 -0.219153  0.232538  ... -0.050691 -0.023590 -0.066722 -0.025083   \n",
       "3 -0.194347 -0.098181  0.270375  ... -0.136009 -0.177037 -0.130498 -0.054766   \n",
       "4 -0.265423 -0.172700  0.266434  ... -0.048885 -0.053074 -0.088550 -0.031346   \n",
       "\n",
       "   MFCCs_21  MFCCs_22           Family      Genus         Species  RecordID  \n",
       "0  0.118680  0.014038  Leptodactylidae  Adenomera  AdenomeraAndre         1  \n",
       "1  0.082263  0.029056  Leptodactylidae  Adenomera  AdenomeraAndre         1  \n",
       "2  0.099108  0.077162  Leptodactylidae  Adenomera  AdenomeraAndre         1  \n",
       "3 -0.018691  0.023954  Leptodactylidae  Adenomera  AdenomeraAndre         1  \n",
       "4  0.108610  0.079244  Leptodactylidae  Adenomera  AdenomeraAndre         1  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Frogs.shape)\n",
    "Frogs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Frogs_train, Frogs_test = train_test_split(Frogs, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frogs['RecordID'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Train a classifier for each label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (i) Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Exact Match**: this uses Exact Match Ratio to extend the accuracy used in single label case for multi-label prediction. The predicted labels and the true labels are exactly matched when the set of labels predicted for a sample exactly match the corresponding set of true labels. <br>\n",
    "\n",
    "* **Hamming score**: often derived from the Hamming Loss, offers a less strict metric by considering the fraction of the correct labels to the total number of labels. It is particularly useful in evaluating the performance of a model on how well it classifies each label. It measures the fraction of the correctly predicted labels to the total number of labels across all samples. It is an adaptation of the Hamming Loss, which counts the proportion of wrongly predicted labels.\n",
    "  $$ \\text{Hamming Score} = 1 - \\text{Hamming Loss} $$\n",
    "  $$ \\text{Hamming Loss} = \\frac{1}{N} \\sum_{i=1}^{N} \\frac{1}{L} \\sum_{l=1}^{L} \\mathbb{1}(y_{i,l} \\neq \\hat{y}_{i,l}) $$\n",
    "\n",
    "    The Hamming Score closer to 1 indicates better performance, reflecting a higher proportion of correctly predicted labels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (ii) Train a SVM for each of the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating features and labels \n",
    "X_train = Frogs_train.iloc[:, :-4]\n",
    "X_test = Frogs_test.iloc[:, :-4]\n",
    "labels = ['Family', 'Genus', 'Species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Family\n",
      "Done with Family\n",
      "Processing Genus\n",
      "Done with Genus\n",
      "Processing Species\n",
      "Done with Species\n"
     ]
    }
   ],
   "source": [
    "# parameter grid\n",
    "param_grid = {\n",
    "    'estimator__C': np.logspace(-1, 4, 5),\n",
    "    'estimator__gamma': np.linspace(0.1, 2, 5)\n",
    "}\n",
    "\n",
    "# scorer\n",
    "scorer = make_scorer(accuracy_score)\n",
    "\n",
    "raw_results = {}\n",
    "y_pred_full = np.empty((X_test.shape[0], 0), dtype=int)\n",
    "\n",
    "\n",
    "# Training SVM for each label on raw data\n",
    "for label in labels:\n",
    "    print(f\"Processing {label}\")\n",
    "\n",
    "    y_train = Frogs_train[label]\n",
    "    y_test = Frogs_test[label]\n",
    "    \n",
    "    svm_raw = OneVsRestClassifier(SVC(kernel='rbf'))\n",
    "    grid_search_raw = GridSearchCV(svm_raw, param_grid, scoring=scorer, cv=10)\n",
    "    grid_search_raw.fit(X_train, y_train)\n",
    "    raw_best_params = grid_search_raw.best_params_\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    y_pred_raw = grid_search_raw.predict(X_test)\n",
    "    raw_test_score = accuracy_score(y_test, y_pred_raw)\n",
    "    raw_hamming_loss = hamming_loss(y_test, y_pred_raw)\n",
    "    \n",
    "    # results \n",
    "    raw_results[label] = {\n",
    "        'best_params': raw_best_params,\n",
    "        'test_score': raw_test_score,\n",
    "        'hamming_loss': raw_hamming_loss\n",
    "    }\n",
    "    print(f\"Done with {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: Family, Best Params: {'estimator__C': 31.622776601683793, 'estimator__gamma': 2.0}, Test Score: 0.9958314034275128, Hamming Loss: 0.0041685965724872626\n",
      "Label: Genus, Best Params: {'estimator__C': 31.622776601683793, 'estimator__gamma': 2.0}, Test Score: 0.9911996294580825, Hamming Loss: 0.008800370541917554\n",
      "Label: Species, Best Params: {'estimator__C': 31.622776601683793, 'estimator__gamma': 2.0}, Test Score: 0.9916628068550255, Hamming Loss: 0.008337193144974525\n"
     ]
    }
   ],
   "source": [
    "# results\n",
    "for label, result in raw_results.items():\n",
    "    print(f\"Label: {label}, Best Params: {result['best_params']}, Test Score: {result['test_score']}, Hamming Loss: {result['hamming_loss']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iii) Repeat 1(b)ii with L1-penalized SVMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Family\n",
      "Label: Family, Best Params: {'onevsrestclassifier__estimator__C': 1.7782794100389228}, Test Score: 0.9282075034738305, Hamming Loss: 0.07179249652616952\n",
      "Processing Genus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xopan/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/xopan/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: Genus, Best Params: {'onevsrestclassifier__estimator__C': 31.622776601683793}, Test Score: 0.9416396479851783, Hamming Loss: 0.058360352014821676\n",
      "Processing Species\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xopan/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: Species, Best Params: {'onevsrestclassifier__estimator__C': 1.7782794100389228}, Test Score: 0.9587772116720704, Hamming Loss: 0.041222788327929596\n"
     ]
    }
   ],
   "source": [
    "# Parameter grid\n",
    "param_grid = {\n",
    "    'onevsrestclassifier__estimator__C': np.logspace(-1, 4, 5)\n",
    "}\n",
    "\n",
    "l1_results = {}\n",
    "y_pred_full = np.empty((X_test.shape[0], 0))  # For collecting all label predictions\n",
    "\n",
    "\n",
    "# Training L1-penalized SVM for each label on standardized data\n",
    "for label in labels:\n",
    "    print(f\"Processing {label}\")\n",
    "\n",
    "    y_train = Frogs_train[label]\n",
    "    y_test = Frogs_test[label]\n",
    "    \n",
    "    # Create a pipeline for standardization and L1-penalized SVM\n",
    "    l1_svm = make_pipeline(StandardScaler(), OneVsRestClassifier(LinearSVC(penalty='l1', dual=False, max_iter=30000)))\n",
    "    grid_search_l1 = GridSearchCV(l1_svm, param_grid, scoring='accuracy', cv=10)\n",
    "    grid_search_l1.fit(X_train, y_train)\n",
    "    l1_best_params = grid_search_l1.best_params_\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    y_pred = grid_search_l1.predict(X_test)\n",
    "    y_pred_full = np.column_stack((y_pred_full, y_pred))  # Collecting predictions\n",
    "    \n",
    "    l1_test_score = accuracy_score(y_test, y_pred)\n",
    "    l1_hamming_loss = hamming_loss(y_test, y_pred)\n",
    "    \n",
    "    # Results for L1-penalized SVM\n",
    "    l1_results[label] = {\n",
    "        'best_params': l1_best_params,\n",
    "        'test_score': l1_test_score,\n",
    "        'hamming_loss': l1_hamming_loss\n",
    "    }\n",
    "    \n",
    "    print(f'Label: {label}, Best Params: {l1_best_params}, Test Score: {l1_test_score}, Hamming Loss: {l1_hamming_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iv) Repeat 1(b)iii by using SMOTE or any other method for imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Family\n",
      "Done with Family\n",
      "Processing Genus\n",
      "Done with Genus\n",
      "Processing Species\n",
      "Done with Species\n",
      "Label: Family\n",
      "  Best Params: {'onevsrestclassifier__estimator__C': 31.622776601683793}, Test Score: 0.9092172301991662, Hamming Loss: 0.09078276980083372\n",
      "Label: Genus\n",
      "  Best Params: {'onevsrestclassifier__estimator__C': 562.341325190349}, Test Score: 0.9018063918480778, Hamming Loss: 0.09819360815192218\n",
      "Label: Species\n",
      "  Best Params: {'onevsrestclassifier__estimator__C': 1.7782794100389228}, Test Score: 0.9573876794812413, Hamming Loss: 0.042612320518758684\n"
     ]
    }
   ],
   "source": [
    "# Parameter grid\n",
    "param_grid = {\n",
    "    'onevsrestclassifier__estimator__C': np.logspace(-1, 4, 5)\n",
    "}\n",
    "\n",
    "# Scorer\n",
    "scorer = make_scorer(accuracy_score)\n",
    "\n",
    "\n",
    "smote_results = {}\n",
    "\n",
    "# using SMOTE for class balancing\n",
    "for label in labels:\n",
    "    print(f\"Processing {label}\")\n",
    "   \n",
    "    y_train_label = Frogs_train[label]\n",
    "    y_test_label = Frogs_test[label]\n",
    "\n",
    "    # Create a pipeline with SMOTE and L1-penalized SVM\n",
    "    pipeline = make_pipeline_imb(StandardScaler(), SMOTE(random_state=42), \n",
    "                                 OneVsRestClassifier(LinearSVC(penalty='l1', dual=False, max_iter=30000)))\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, scoring=scorer, cv=10)\n",
    "    grid_search.fit(X_train, y_train_label)\n",
    "    \n",
    "    best_params = grid_search.best_params_\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "    test_score = accuracy_score(y_test_label, y_pred)\n",
    "    hamming_loss_value = hamming_loss(y_test_label, y_pred)\n",
    "    \n",
    "    # results\n",
    "    smote_results[label] = {\n",
    "        'best_params': best_params,\n",
    "        'test_score': test_score,\n",
    "        'hamming_loss': hamming_loss_value\n",
    "    }\n",
    "    print(f\"Done with {label}\")\n",
    "\n",
    "# Print results\n",
    "for label, result in smote_results.items():\n",
    "    print(f\"Label: {label}\")\n",
    "    print(f\"  Best Params: {result['best_params']}, Test Score: {result['test_score']}, Hamming Loss: {result['hamming_loss']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. K-Means Clustering on a Multi-Class and Multi-Label Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results based on 50 Monte Carlo. We combine parts (a), (b) and (c) together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding optimal k: 100%|██████████| 50/50 [29:38<00:00, 35.57s/it]\n"
     ]
    }
   ],
   "source": [
    "# the code without Monte Carlo\n",
    "X = Frogs.drop(['Family', 'Genus', 'Species', 'RecordID'], axis=1)\n",
    "true_labels = Frogs[['Family', 'Genus', 'Species']]\n",
    "\n",
    "max_k = 50\n",
    "optimal_k_list, hamming_distance, hamming_score = [], [], []\n",
    "\n",
    "for simulation in tqdm(range(50), desc=\"Finding optimal k\"):\n",
    "    # Finding the optimal k for each simulation\n",
    "    silhouette_scores = []\n",
    "    for k in range(2, max_k + 1):\n",
    "        kmeans = KMeans(n_clusters=k, random_state=simulation, n_init=1).fit(X)\n",
    "        labels = kmeans.labels_\n",
    "        silhouette_scores.append(silhouette_score(X, labels))\n",
    "    optimal_k = np.argmax(silhouette_scores) + 2  # Adjust for 0-indexing\n",
    "    optimal_k_list.append(optimal_k)\n",
    "    # Re-cluster with the most common optimal k\n",
    "    kmeans = KMeans(n_clusters=optimal_k, random_state=simulation, n_init=1).fit(X)\n",
    "    labels = kmeans.labels_\n",
    "    ## determine the majority label\n",
    "    Frogs['Cluster'] = labels\n",
    "    majority_labels = Frogs.groupby('Cluster').agg(lambda x: x.value_counts().idxmax())\n",
    "    ## calculate the hamming distance and score\n",
    "    total_hamming_distance = 0\n",
    "    for label in ['Family', 'Genus', 'Species']:\n",
    "        # Calculate Hamming distance by comparing the predicted majority label to the actual labels\n",
    "        predicted_labels = Frogs['Cluster'].map(majority_labels[label])\n",
    "        total_hamming_distance += hamming_loss(true_labels[label], predicted_labels)\n",
    "    hamming_distance.append(total_hamming_distance / 3)\n",
    "    hamming_score.append(1.0 - total_hamming_distance / 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>optimal_k</th>\n",
       "      <th>hamming_distance</th>\n",
       "      <th>hamming_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.352791</td>\n",
       "      <td>0.647209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.281260</td>\n",
       "      <td>0.718740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.352791</td>\n",
       "      <td>0.647209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.281260</td>\n",
       "      <td>0.718740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0.281260</td>\n",
       "      <td>0.718740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>0.281260</td>\n",
       "      <td>0.718740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>0.352791</td>\n",
       "      <td>0.647209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>0.352791</td>\n",
       "      <td>0.647209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>0.352791</td>\n",
       "      <td>0.647209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>0.352791</td>\n",
       "      <td>0.647209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>0.281260</td>\n",
       "      <td>0.718740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>0.352791</td>\n",
       "      <td>0.647209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>0.281260</td>\n",
       "      <td>0.718740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>0.352791</td>\n",
       "      <td>0.647209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>0.352791</td>\n",
       "      <td>0.647209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>0.281260</td>\n",
       "      <td>0.718740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>0.281260</td>\n",
       "      <td>0.718740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>0.352791</td>\n",
       "      <td>0.647209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>0.281260</td>\n",
       "      <td>0.718740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>0.281260</td>\n",
       "      <td>0.718740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3</td>\n",
       "      <td>0.281260</td>\n",
       "      <td>0.718740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3</td>\n",
       "      <td>0.281260</td>\n",
       "      <td>0.718740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3</td>\n",
       "      <td>0.281260</td>\n",
       "      <td>0.718740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>0.352791</td>\n",
       "      <td>0.647209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>0.352791</td>\n",
       "      <td>0.647209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3</td>\n",
       "      <td>0.281260</td>\n",
       "      <td>0.718740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>0.352791</td>\n",
       "      <td>0.647209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3</td>\n",
       "      <td>0.281260</td>\n",
       "      <td>0.718740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>0.352791</td>\n",
       "      <td>0.647209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3</td>\n",
       "      <td>0.281260</td>\n",
       "      <td>0.718740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3</td>\n",
       "      <td>0.281260</td>\n",
       "      <td>0.718740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2</td>\n",
       "      <td>0.352791</td>\n",
       "      <td>0.647209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2</td>\n",
       "      <td>0.352791</td>\n",
       "      <td>0.647209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2</td>\n",
       "      <td>0.352791</td>\n",
       "      <td>0.647209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2</td>\n",
       "      <td>0.352791</td>\n",
       "      <td>0.647209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3</td>\n",
       "      <td>0.281260</td>\n",
       "      <td>0.718740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3</td>\n",
       "      <td>0.281260</td>\n",
       "      <td>0.718740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2</td>\n",
       "      <td>0.352791</td>\n",
       "      <td>0.647209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2</td>\n",
       "      <td>0.352791</td>\n",
       "      <td>0.647209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>3</td>\n",
       "      <td>0.281260</td>\n",
       "      <td>0.718740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>3</td>\n",
       "      <td>0.281260</td>\n",
       "      <td>0.718740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>3</td>\n",
       "      <td>0.281260</td>\n",
       "      <td>0.718740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2</td>\n",
       "      <td>0.352791</td>\n",
       "      <td>0.647209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2</td>\n",
       "      <td>0.352791</td>\n",
       "      <td>0.647209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2</td>\n",
       "      <td>0.352791</td>\n",
       "      <td>0.647209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>3</td>\n",
       "      <td>0.281260</td>\n",
       "      <td>0.718740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>3</td>\n",
       "      <td>0.281260</td>\n",
       "      <td>0.718740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>3</td>\n",
       "      <td>0.281260</td>\n",
       "      <td>0.718740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>3</td>\n",
       "      <td>0.281260</td>\n",
       "      <td>0.718740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>3</td>\n",
       "      <td>0.281260</td>\n",
       "      <td>0.718740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    optimal_k  hamming_distance  hamming_score\n",
       "0           2          0.352791       0.647209\n",
       "1           3          0.281260       0.718740\n",
       "2           2          0.352791       0.647209\n",
       "3           3          0.281260       0.718740\n",
       "4           3          0.281260       0.718740\n",
       "5           3          0.281260       0.718740\n",
       "6           2          0.352791       0.647209\n",
       "7           2          0.352791       0.647209\n",
       "8           2          0.352791       0.647209\n",
       "9           2          0.352791       0.647209\n",
       "10          3          0.281260       0.718740\n",
       "11          2          0.352791       0.647209\n",
       "12          3          0.281260       0.718740\n",
       "13          2          0.352791       0.647209\n",
       "14          2          0.352791       0.647209\n",
       "15          3          0.281260       0.718740\n",
       "16          3          0.281260       0.718740\n",
       "17          2          0.352791       0.647209\n",
       "18          3          0.281260       0.718740\n",
       "19          3          0.281260       0.718740\n",
       "20          3          0.281260       0.718740\n",
       "21          3          0.281260       0.718740\n",
       "22          3          0.281260       0.718740\n",
       "23          2          0.352791       0.647209\n",
       "24          2          0.352791       0.647209\n",
       "25          3          0.281260       0.718740\n",
       "26          2          0.352791       0.647209\n",
       "27          3          0.281260       0.718740\n",
       "28          2          0.352791       0.647209\n",
       "29          3          0.281260       0.718740\n",
       "30          3          0.281260       0.718740\n",
       "31          2          0.352791       0.647209\n",
       "32          2          0.352791       0.647209\n",
       "33          2          0.352791       0.647209\n",
       "34          2          0.352791       0.647209\n",
       "35          3          0.281260       0.718740\n",
       "36          3          0.281260       0.718740\n",
       "37          2          0.352791       0.647209\n",
       "38          2          0.352791       0.647209\n",
       "39          3          0.281260       0.718740\n",
       "40          3          0.281260       0.718740\n",
       "41          3          0.281260       0.718740\n",
       "42          2          0.352791       0.647209\n",
       "43          2          0.352791       0.647209\n",
       "44          2          0.352791       0.647209\n",
       "45          3          0.281260       0.718740\n",
       "46          3          0.281260       0.718740\n",
       "47          3          0.281260       0.718740\n",
       "48          3          0.281260       0.718740\n",
       "49          3          0.281260       0.718740"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame()\n",
    "results['optimal_k'] = optimal_k_list\n",
    "results['hamming_distance'] = hamming_distance\n",
    "results['hamming_score'] = hamming_score\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3141644660643965, 0.035650944390119566)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(results['hamming_distance']), np.std(results['hamming_distance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal K values, hamming distance and hamming scores are reported in the above table. The average hamming distance is 0.31 and the standard deviation of hamming distance is 0.036."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [multilabel-classification](https://stats.stackexchange.com/questions/233275/multilabel-classification-metrics-on-scikit)\n",
    "* [multilabel_classification_metrics](https://mmuratarat.github.io/2020-01-25/multilabel_classification_metrics)\n",
    "* [multi-label-classifiers](https://towardsdatascience.com/evaluating-multi-label-classifiers-a31be83da6ea)\n",
    "* [tqdm](https://pypi.org/project/tqdm/)\n",
    "* [LinearSVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html)\n",
    "* [SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)\n",
    "* [make_scorer](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html)\n",
    "* [hamming_loss](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.hamming_loss.html)\n",
    "* [OneVsRestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html)\n",
    "* [make_pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html)\n",
    "* [Over_sampling.SMOTE](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html)\n",
    "* [silhouette_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html)\n",
    "* [squareform](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.squareform.html)\n",
    "* [linkage](https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html)\n",
    "* [dendrogram](https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.dendrogram.html)\n",
    "* [dendrogram II](https://stackoverflow.com/questions/41416498/dendrogram-or-other-plot-from-distance-matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "3c20c2d94d2527936fe0f3a300eb11db30fed84423423838e2f93b74eb7aaebc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
